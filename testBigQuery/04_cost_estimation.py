from google.cloud import bigquery

# åˆå§‹åŒ–
PROJECT_ID = "webeye-internal-test"
client = bigquery.Client(project=PROJECT_ID)

def estimate_query_cost():
    """æ¼”ç¤º Dry Run (é¢„è¿è¡Œ) æ¥ä¼°ç®—æˆæœ¬"""
    
    # è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤§çš„ Public Data æŸ¥è¯¢ (Wikipedia è®¿é—®è®°å½•)
    # å¦‚æœä¸åŠ  LIMIT ç›´æ¥è·‘ï¼Œæˆ–è€…ä¸å°å¿ƒå†™äº† SELECT *ï¼Œæ•°æ®é‡å¯èƒ½å¾ˆå¤§
    query = """
        SELECT wiki, title, SUM(views) as total_views
        FROM `bigquery-public-data.wikipedia.pageviews_2020`
        WHERE date(datehour) = '2020-01-01'
        GROUP BY wiki, title
        ORDER BY total_views DESC
        LIMIT 10
    """

    # 1. é…ç½® Dry Run
    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)

    # 2. å‘èµ·æŸ¥è¯¢è¯·æ±‚ (æ­¤æ—¶ä¸ä¼šçœŸæ­£è¿è¡Œï¼Œä¹Ÿä¸ä¼šè®¡è´¹)
    query_job = client.query(query, job_config=job_config)

    # 3. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    bytes_processed = query_job.total_bytes_processed
    gb_processed = bytes_processed / (1024 * 1024 * 1024)
    
    print(f"--- æˆæœ¬é¢„ä¼° ---")
    print(f"æ­¤æŸ¥è¯¢å°†æ‰«æ: {bytes_processed} å­—èŠ‚")
    print(f"çº¦åˆ: {gb_processed:.2f} GB")
    
    # BigQuery å…è´¹é¢åº¦é€šå¸¸æ˜¯æ¯æœˆ 1TB (On-demand)
    # å‡è®¾ä»·æ ¼æ˜¯ $5.00 per TB (å…·ä½“çœ‹åŒºåŸŸ)
    cost = (bytes_processed / (1024 ** 4)) * 5.00
    print(f"é¢„è®¡è´¹ç”¨ (æŒ‰ $5/TB è®¡ç®—): ${cost:.4f}")

    # å¦‚æœä½ èƒ½æ¥å—è¿™ä¸ªæˆæœ¬ï¼Œå†æŠŠ dry_run=False çœŸæ­£è·‘ä¸€æ¬¡
    # real_job = client.query(query) ...


def run_safe_query_with_limit():
    """æ¼”ç¤ºä½¿ç”¨ maximum_bytes_billed ä½œä¸ºå®‰å…¨æ–­è·¯å™¨"""
    print("\n--- å®‰å…¨æŸ¥è¯¢æ¼”ç¤º (Maximum Bytes Billed) ---")
    
    query = """
        SELECT wiki, title, SUM(views) as total_views
        FROM `bigquery-public-data.wikipedia.pageviews_2020`
        WHERE date(datehour) = '2020-01-01'
        GROUP BY wiki, title
        ORDER BY total_views DESC
        LIMIT 10
    """
    
    # è®¾ç½®ç¡¬é™åˆ¶ï¼šä¾‹å¦‚ 100 MB
    # ğŸ’¡ æœ€ä½³å®è·µ: åœ¨æ‰€æœ‰ç”Ÿäº§ç¯å¢ƒæŸ¥è¯¢ä¸­ï¼Œéƒ½åº”è¯¥æ ¹æ®é¢„ä¼°è®¾ç½®è¿™ä¸ªå€¼ã€‚
    # å®ƒå……å½“â€œç†”æ–­å™¨â€ï¼Œé˜²æ­¢å› ä¸ºæ‰‹è¯¯å†™é”™ SQL (å¦‚æ¼æ‰åˆ†åŒºæ¡ä»¶) å¯¼è‡´äº§ç”Ÿå¤©ä»·è´¦å•ã€‚
    _limit_mb = 1
    LIMIT_BYTES = _limit_mb * 1024 * 1024 
    
    job_config = bigquery.QueryJobConfig(
        maximum_bytes_billed=LIMIT_BYTES
    )

    try:
        print(f"å°è¯•è¿è¡ŒæŸ¥è¯¢ï¼Œç”±äº maximum_bytes_billed è®¾ç½®ä¸º {LIMIT_BYTES} å­—èŠ‚ ({_limit_mb}MB)...")
        # çœŸæ­£å‘èµ·æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ dry_run
        query_job = client.query(query, job_config=job_config)
        results = query_job.result() # ç­‰å¾…å®Œæˆ
        print("æŸ¥è¯¢æˆåŠŸå®Œæˆ (è¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œé™¤éæ•°æ®é‡å¾ˆå°)")
        
    except Exception as e:
        print("\n[é¢„æœŸå†…çš„æŠ¥é”™] æŸ¥è¯¢è¢«æ‹¦æˆªäº†ï¼è¿™å¸®ä½ çœé’±äº†ã€‚")
        print(f"é”™è¯¯è¯¦æƒ…: {e}")

if __name__ == "__main__":
    estimate_query_cost()
    run_safe_query_with_limit()
